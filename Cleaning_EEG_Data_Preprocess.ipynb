{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning EEG Data Preprocess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU4mL8qQ3KMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import copy\n",
        "import random\n",
        "import scipy.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oHey4nkV0BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d87d7612-73e2-484b-a64a-aeb418ecfae4"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78W7_IINUGEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Read data from txt format produced by EEGLAB to numpy array and optionally save numpy arrays to CSV in Google Drive ###\n",
        "### NOTE: This version allows creating random sample groups within a given (subject + dosage)\n",
        "### This is useful, for example, to allow the model to choose one of N samples to base a classification off of\n",
        "pathInMyDrive = \"PsiloClassifier/txtDownsampledData/\"\n",
        "pathToSaveData = \"PsiloClassifier/dataSplit/\"\n",
        "\n",
        "allSubjects = [\"01\", \"02\", \"04\", \"05\", \"08\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
        "testSubjects = [\"02\", \"08\", \"15\", \"23\"]\n",
        "valSubjects = [\"05\", \"16\"]\n",
        "trainSubjects = [x for x in allSubjects if x not in (testSubjects + valSubjects)]\n",
        "\n",
        "selectEveryNthChannelN = 2\n",
        "sampleLength = 250\n",
        "saveToDisk = True\n",
        "dataVersion = \"3\"\n",
        "groupSize = 3\n",
        "\n",
        "trainX, trainY, testX, testY, valX, valY = load(selectEveryNthChannelN, sampleLength, groupSize)\n",
        "\n",
        "if(saveToDisk):\n",
        "  scipy.io.savemat(pathToSaveData + \"trainX\" + dataVersion + \".mat\", mdict={'trainX': trainX}, oned_as='row')\n",
        "  scipy.io.savemat(pathToSaveData + \"trainY\" + dataVersion + \".mat\", mdict={'trainY': trainY}, oned_as='row')\n",
        "  scipy.io.savemat(pathToSaveData + \"valX\" + dataVersion + \".mat\", mdict={'valX': valX}, oned_as='row')\n",
        "  scipy.io.savemat(pathToSaveData + \"valY\" + dataVersion + \".mat\", mdict={'valY': valY}, oned_as='row')\n",
        "  scipy.io.savemat(pathToSaveData + \"testX\" + dataVersion + \".mat\", mdict={'testX': testX}, oned_as='row')\n",
        "  scipy.io.savemat(pathToSaveData + \"testY\" + dataVersion + \".mat\", mdict={'testY': testY}, oned_as='row')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fUbl0Hg7x5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to check that data saved to disk is correct:\n",
        "matdata = scipy.io.loadmat(pathToSaveData + \"testX\" + dataVersion + \".mat\")\n",
        "assert np.all(testX == matdata['testX'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8riDNhUkV8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#subject, timestamp, sample_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_n8qOgTHmLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(selectEveryNthChannelN, sampleLength, groupSize):\n",
        "  trainXPlacebo, trainYPlacebo = loadProcess(trainSubjects, \"PL\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  trainXHD, trainYHD = loadProcess(trainSubjects, \"HD\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  trainX, trainY = catAndShuffleData(trainXPlacebo, trainYPlacebo, trainXHD, trainYHD)\n",
        "\n",
        "  testXPlacebo, testYPlacebo = loadProcess(testSubjects, \"PL\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  testXHD, testYHD = loadProcess(testSubjects, \"HD\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  testX, testY = catAndShuffleData(testXPlacebo, testYPlacebo, testXHD, testYHD)\n",
        "\n",
        "  valXPlacebo, valYPlacebo = loadProcess(valSubjects, \"PL\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  valXHD, valYHD = loadProcess(valSubjects, \"HD\", selectEveryNthChannelN, sampleLength, groupSize)\n",
        "  valX, valY = catAndShuffleData(valXPlacebo, valYPlacebo, valXHD, valYHD)\n",
        "\n",
        "  return trainX, trainY, testX, testY, valX, valY;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5drdmbwOR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadProcess(subjectList, dose, selectEveryNthChannelN, sampleLength, groupSize):\n",
        "  x = loadDownsampledDataFromSubjectListAndDose(subjectList, dose)\n",
        "  x = keepEveryNthDataChannel(x, selectEveryNthChannelN)\n",
        "  x = segmentChannelsIntoVectors(x, sampleLength)\n",
        "  x = standardizeDataVectors(x)\n",
        "  x = np.array(x)\n",
        "  x = groupSelectedSampleCombinations(x, groupSize)\n",
        "  x = combineSubjectsTogether(x)\n",
        "  y = []\n",
        "  if dose == \"PL\":\n",
        "    for i in range(x.shape[0]):\n",
        "      y.append(np.zeros(1))\n",
        "  else:\n",
        "    for i in range(x.shape[0]):\n",
        "      y.append(np.ones(1))\n",
        "  y = np.array(y)\n",
        "  return x, y;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yRpVjm4YQ6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadDownsampledDataFromSubjectListAndDose(subjectList, dose):\n",
        "  dataList = []\n",
        "  for i in subjectList:\n",
        "    filename = \"S\" + i + \"_P300_\" + dose + \"_125.txt\"\n",
        "    dataList.append(loadtxt(pathInMyDrive + filename,  delimiter='\\t'))\n",
        "  return dataList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtAspHsDcXml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keepEveryNthDataChannel(subjectDataList, n):\n",
        "  dataList = []\n",
        "  for subjectDataset in subjectDataList:\n",
        "    dataList.append(subjectDataset[:, 0::n])\n",
        "  return dataList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1eD6E4k0QYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentChannelsIntoVectors(subjectDataList, vectorLength):\n",
        "  dataList = []\n",
        "  for subjectDataset in subjectDataList:\n",
        "    dataVectors = []\n",
        "    for channel in range(np.size(subjectDataset, 1)):\n",
        "      time = int(np.random.uniform(0, vectorLength))\n",
        "      while (time + vectorLength) < np.size(subjectDataset, 0):\n",
        "        dataVectors.append(subjectDataset[time : time + vectorLength , channel])\n",
        "        time = time + vectorLength    \n",
        "    dataList.append(dataVectors) #each element in \"dataList\" contains vector sample from one subject              \n",
        "  return dataList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-tAUR1lYs80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def groupSelectedSampleCombinations(x, groupSize):\n",
        "  temp_deep_copy = copy.deepcopy(x)\n",
        "  for sub_index, subject in enumerate(x):\n",
        "    num_samples = len(subject)\n",
        "    for samp_index, sample in enumerate(subject):\n",
        "      for i in range(groupSize - 1):\n",
        "        r = list(range(0, samp_index)) + list(range(samp_index+1, num_samples))\n",
        "        rand_index = random.choice(r)\n",
        "        x[sub_index][samp_index] = np.column_stack((x[sub_index][samp_index], temp_deep_copy[sub_index][rand_index]))\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPReYDuittzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combineSubjectsTogether(x):\n",
        "  for i, ls in enumerate(x):\n",
        "    x[i] = np.array(ls)\n",
        "  dataList = []\n",
        "  for subject in x:\n",
        "    for mat in subject:\n",
        "      dataList.append(mat)\n",
        "  combinedX = np.array(dataList)\n",
        "  return combinedX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkI2HujlGr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardizeDataVectors(dataSubjectVectorList):\n",
        "  dataList = []\n",
        "  for subject in dataSubjectVectorList:\n",
        "    dataVectors = []\n",
        "    for vec in subject:\n",
        "      mean = np.mean(vec)\n",
        "      stdev = np.std(vec)\n",
        "      standardVec = (vec - mean)/stdev\n",
        "      dataVectors.append(standardVec)\n",
        "    dataList.append(dataVectors)\n",
        "  return dataList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNXbZuM9G33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def catAndShuffleData(x0, y0, x1, y1):\n",
        "  x = np.concatenate((x0, x1), axis=0)\n",
        "  y = np.concatenate((y0, y1), axis=0)\n",
        "\n",
        "  x, y = shuffle(x, y)\n",
        "\n",
        "  return x, y;"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}