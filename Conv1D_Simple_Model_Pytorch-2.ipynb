{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv1D_Simple_Model_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFEdcFcHCAG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti9NunI6CIM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "daf5da82-7d85-4cd1-e3d9-6fbdec99ed4b"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXX-B4wUIXt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(isCONVfirstLayer, valPercentage):\n",
        "  trainX = np.loadtxt(\"PsiloClassifier/dataSplit/trainX2.csv\", delimiter= \",\")\n",
        "  trainY = np.loadtxt(\"PsiloClassifier/dataSplit/trainY2.csv\", delimiter= \",\")\n",
        "  testX = np.loadtxt(\"PsiloClassifier/dataSplit/testX2.csv\", delimiter= \",\")\n",
        "  testY = np.loadtxt(\"PsiloClassifier/dataSplit/testY2.csv\", delimiter= \",\")\n",
        "  valX = np.loadtxt(\"PsiloClassifier/dataSplit/valX2.csv\", delimiter= \",\")\n",
        "  valY = np.loadtxt(\"PsiloClassifier/dataSplit/valY2.csv\", delimiter= \",\")\n",
        "  \n",
        "  if(isCONVfirstLayer):\n",
        "    shape = trainX.shape\n",
        "    samples = shape[0]\n",
        "    timesteps = shape[1]\n",
        "    trainX = trainX.reshape(samples, 1, timesteps)\n",
        "\n",
        "    shape= testX.shape\n",
        "    samples = shape[0]\n",
        "    timesteps = shape[1]\n",
        "    testX = testX.reshape(samples, 1, timesteps)\n",
        "\n",
        "    shape= valX.shape\n",
        "    samples = shape[0]\n",
        "    timesteps = shape[1]\n",
        "    valX = valX.reshape(samples, 1, timesteps)\n",
        "\n",
        "  trainX = trainX.astype('float32')\n",
        "  testX = testX.astype('float32')\n",
        "  valX = valX.astype('float32')\n",
        "  trainY = trainY.astype('float32').reshape((-1,1))\n",
        "  testY = testY.astype('float32').reshape((-1,1))\n",
        "  valY = valY.astype('float32').reshape((-1,1))\n",
        "\n",
        "  trainX = torch.tensor(trainX)\n",
        "  trainY = torch.tensor(trainY)\n",
        "  testX = torch.tensor(testX)\n",
        "  testY = torch.tensor(testY)\n",
        "  valX = torch.tensor(valX)\n",
        "  valY = torch.tensor(valY)\n",
        "\n",
        "  return trainX, trainY, valX, valY, testX, testY"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV6C4UV-TsH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDataset(trainX, trainY, valX, valY):\n",
        "  train_ds = TensorDataset(trainX, trainY)\n",
        "  val_ds = TensorDataset(valX, valY)\n",
        "  return train_ds, val_ds"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXwnDjsWUKuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDataLoaders(train_ds, val_ds, bs):\n",
        "  train_dl = DataLoader(train_ds, bs, shuffle=False)\n",
        "  val_dl = DataLoader(val_ds, bs, shuffle=False)\n",
        "  return train_dl, val_dl"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wkLPdTH1EF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def c_out_length(in_length, kernel_size, padding=0, dilation=1, stride=1):\n",
        "  length_out = ((in_length + 2*padding - dilation*(kernel_size - 1) - 1) / stride ) + 1\n",
        "  return length_out\n",
        "\n",
        "class ConvClassifier(nn.Module):\n",
        "  def __init__(self, sample_length, num_filters, kernel_size, pool_kernel_size, output_dim):\n",
        "    super().__init__()\n",
        "    self.sample_length = sample_length\n",
        "    self.num_filters = num_filters\n",
        "    self.pool_kernel_size = pool_kernel_size\n",
        "\n",
        "    self.conv = nn.Conv1d(1, num_filters, kernel_size)\n",
        "    self.pool = nn.MaxPool1d(pool_kernel_size)\n",
        "    \n",
        "    conv_out_length = c_out_length(sample_length, kernel_size)\n",
        "    pool_out_length = int(conv_out_length/pool_kernel_size)\n",
        "    fully_connected_input = int(pool_out_length * num_filters)\n",
        "\n",
        "    self.fc_input = fully_connected_input\n",
        "    self.fc = nn.Linear(fully_connected_input, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, self.fc_input)\n",
        "    x = self.fc(x)\n",
        "    x = sigmoid(x)\n",
        "    return x\n",
        "\n",
        "def accuracyAndLoss(data_loader, model):\n",
        "  total, correct, loss, batches = 0, 0, 0, 0\n",
        "  model.eval()\n",
        "  for x, y in data_loader:\n",
        "    out = model(x)\n",
        "    preds = out.round()\n",
        "    total += y.size(0)\n",
        "    batches += 1\n",
        "    correct += (preds == y).sum().item()\n",
        "    loss += criterion(out, y)\n",
        "  return correct/total, loss/batches"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CscN6OQl0HNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX, trainY, valX, valY, testX, testY = loadData(True, 20)\n",
        "train_ds, val_ds = createDataset(trainX, trainY, valX, valY)\n",
        "train_dl, val_dl = createDataLoaders(train_ds, val_ds, bs=512)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFH3RFNOuV4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(lr, epochs, sample_length, num_filters, kernel_size, pool_kernel_size, plot=False):\n",
        "  model = ConvClassifier(sample_length, num_filters, kernel_size, pool_kernel_size, 1)\n",
        "  criterion = nn.BCELoss()\n",
        "  opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "  train_accuracy = []\n",
        "  val_accuracy = []\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "\n",
        "  print('Starting model training... lr:', lr, ' epochs:', epochs,  ' num_filters:', num_filters, ' kernel_size:', kernel_size, ' pool_kernel_size:', pool_kernel_size)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for i, (x_batch, y_batch) in enumerate(train_dl):\n",
        "          model.train()\n",
        "          x_batch = x_batch\n",
        "          y_batch = y_batch\n",
        "          opt.zero_grad()\n",
        "          out = model(x_batch)\n",
        "          loss = criterion(out, y_batch)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        train_accuracy_, train_loss_ = accuracyAndLoss(train_dl, model)\n",
        "        train_accuracy.append(train_accuracy_)\n",
        "        train_loss.append(train_loss_)\n",
        "        val_accuracy_, val_loss_ = accuracyAndLoss(val_dl, model)\n",
        "        val_accuracy.append(val_accuracy_)\n",
        "        val_loss.append(val_loss_)\n",
        "\n",
        "  if plot == True: \n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(train_accuracy, 'b')\n",
        "    plt.title(\"accuracy\")\n",
        "    plt.plot(val_accuracy, 'r')\n",
        "\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.plot(train_loss, 'b')\n",
        "    plt.title(\"loss\")\n",
        "    plt.plot(val_loss, 'r')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  print('Training complete! train_accuracy:', round(train_accuracy[-1], 3), ' val_accuracy:', round(val_accuracy[-1], 3), ' train_loss:', round(train_loss[-1].item(), 3), ' val_loss:', round(val_loss[-1].item(), 3) )\n",
        "\n",
        "  return train_accuracy, val_accuracy, train_loss, val_loss, model;"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B8s6orwbHSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stores all information relevant to a model trained using random parameter search\n",
        "class trainedModel:\n",
        "  def __init__(self, lr, epochs, num_filters, kernel_size, pool_kernel_size, train_accuracy, val_accuracy, train_loss, val_loss):\n",
        "    self.lr = lr\n",
        "    self.epochs = epochs\n",
        "    self.num_filters = num_filters\n",
        "    self.kernel_size = kernel_size\n",
        "    self.pool_kernel_size = pool_kernel_size\n",
        "    self.train_accuracy = train_accuracy\n",
        "    self.val_accuracy = val_accuracy\n",
        "    self.train_loss = train_loss\n",
        "    self.val_loss = val_loss\n",
        "    self.final_val_accuracy = val_accuracy[-1]\n",
        "\n",
        "  def __gt__(self, other):\n",
        "    return self.final_val_accuracy > other.final_val_accuracy\n",
        "\n",
        "#searches for optimal parameters within intervals of lr, epoch, etc. using uniform distribution. keeps and returns top 10 model objects (not their parameters, just their hyperparameters)\n",
        "def paramSearch(reps, lr_min, lr_max, epoch_min, epoch_max, nf_min, nf_max, ks_min, ks_max, pks_min, pks_max):\n",
        "  num_models_to_keep = 10\n",
        "  best_trained_models = []\n",
        "\n",
        "  for rep in range(reps):\n",
        "    lr = np.random.uniform(lr_min, lr_max)\n",
        "    epochs = int(np.random.uniform(epoch_min, epoch_max))\n",
        "    num_filters = int(np.random.uniform(nf_min, nf_max))\n",
        "    kernel_size = int(np.random.uniform(ks_min, ks_max))\n",
        "    pool_kernel_size = int(np.random.uniform(pks_min, pks_max))\n",
        "\n",
        "    train_accuracy, val_accuracy, train_loss, val_loss, model = train_model(lr, epochs, 250, num_filters, kernel_size, pool_kernel_size, plot=False)\n",
        "    trained_model = trainedModel(lr, epochs, num_filters, kernel_size, pool_kernel_size, train_accuracy, val_accuracy, train_loss, val_loss)\n",
        "\n",
        "    if len(best_trained_models) < num_models_to_keep: \n",
        "      best_trained_models.append(trained_model)\n",
        "      best_trained_models.sort(key=lambda x: x.final_val_accuracy, reverse=True)\n",
        "    else:\n",
        "      if trained_model > best_trained_models[num_models_to_keep - 1]:\n",
        "        best_trained_models[num_models_to_keep - 1] = trained_model\n",
        "        best_trained_models.sort(key=lambda x: x.final_val_accuracy, reverse=True)\n",
        "\n",
        "  for i, x in enumerate(best_trained_models):\n",
        "    print(i,': ' , x.final_val_accuracy, ' lr: ', x.lr, ' epochs:', x.epochs, ' num_filters:', x.num_filters, ' kernel_size:', x.kernel_size, ' pool_kernel_size:', x.pool_kernel_size)\n",
        "  return best_trained_models"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBVnOfEgkAvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee72060a-0f56-4526-bc66-7548c6f59067"
      },
      "source": [
        "x = []\n",
        "x = paramSearch(40, 0.001, 0.02, 1, 6, 1, 10, 5, 100, 5, 100)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting model training... lr: 0.017860190015564006  epochs: 3  num_filters: 7  kernel_size: 39  pool_kernel_size: 34\n",
            "Training complete! train_accuracy: 0.674  val_accuracy: 0.658  train_loss: 0.59  val_loss: 0.648\n",
            "Starting model training... lr: 0.0018175153660627778  epochs: 2  num_filters: 9  kernel_size: 99  pool_kernel_size: 89\n",
            "Training complete! train_accuracy: 0.668  val_accuracy: 0.644  train_loss: 0.599  val_loss: 0.671\n",
            "Starting model training... lr: 0.008224223587072546  epochs: 5  num_filters: 2  kernel_size: 77  pool_kernel_size: 95\n",
            "Training complete! train_accuracy: 0.649  val_accuracy: 0.638  train_loss: 0.618  val_loss: 0.667\n",
            "Starting model training... lr: 0.015430089687711274  epochs: 5  num_filters: 2  kernel_size: 82  pool_kernel_size: 69\n",
            "Training complete! train_accuracy: 0.664  val_accuracy: 0.643  train_loss: 0.603  val_loss: 0.659\n",
            "Starting model training... lr: 0.009189315409368789  epochs: 4  num_filters: 9  kernel_size: 89  pool_kernel_size: 39\n",
            "Training complete! train_accuracy: 0.681  val_accuracy: 0.634  train_loss: 0.588  val_loss: 0.647\n",
            "Starting model training... lr: 0.013713591056642615  epochs: 1  num_filters: 3  kernel_size: 82  pool_kernel_size: 60\n",
            "Training complete! train_accuracy: 0.662  val_accuracy: 0.647  train_loss: 0.605  val_loss: 0.636\n",
            "Starting model training... lr: 0.01063382782120029  epochs: 4  num_filters: 7  kernel_size: 33  pool_kernel_size: 23\n",
            "Training complete! train_accuracy: 0.675  val_accuracy: 0.656  train_loss: 0.59  val_loss: 0.646\n",
            "Starting model training... lr: 0.0024972920696599834  epochs: 4  num_filters: 5  kernel_size: 48  pool_kernel_size: 5\n",
            "Training complete! train_accuracy: 0.683  val_accuracy: 0.657  train_loss: 0.577  val_loss: 0.658\n",
            "Starting model training... lr: 0.007074937621300964  epochs: 3  num_filters: 6  kernel_size: 39  pool_kernel_size: 29\n",
            "Training complete! train_accuracy: 0.673  val_accuracy: 0.646  train_loss: 0.59  val_loss: 0.653\n",
            "Starting model training... lr: 0.0021537015336468646  epochs: 5  num_filters: 5  kernel_size: 6  pool_kernel_size: 83\n",
            "Training complete! train_accuracy: 0.643  val_accuracy: 0.656  train_loss: 0.622  val_loss: 0.657\n",
            "Starting model training... lr: 0.0024909607697533535  epochs: 4  num_filters: 9  kernel_size: 43  pool_kernel_size: 79\n",
            "Training complete! train_accuracy: 0.673  val_accuracy: 0.65  train_loss: 0.591  val_loss: 0.684\n",
            "Starting model training... lr: 0.0023655828148842523  epochs: 5  num_filters: 2  kernel_size: 86  pool_kernel_size: 14\n",
            "Training complete! train_accuracy: 0.669  val_accuracy: 0.639  train_loss: 0.593  val_loss: 0.692\n",
            "Starting model training... lr: 0.013166648935463706  epochs: 4  num_filters: 6  kernel_size: 66  pool_kernel_size: 16\n",
            "Training complete! train_accuracy: 0.673  val_accuracy: 0.659  train_loss: 0.593  val_loss: 0.631\n",
            "Starting model training... lr: 0.010850930040418889  epochs: 3  num_filters: 3  kernel_size: 12  pool_kernel_size: 22\n",
            "Training complete! train_accuracy: 0.663  val_accuracy: 0.66  train_loss: 0.6  val_loss: 0.653\n",
            "Starting model training... lr: 0.00922938858186918  epochs: 4  num_filters: 3  kernel_size: 84  pool_kernel_size: 70\n",
            "Training complete! train_accuracy: 0.669  val_accuracy: 0.644  train_loss: 0.594  val_loss: 0.671\n",
            "Starting model training... lr: 0.004604750158706846  epochs: 5  num_filters: 7  kernel_size: 91  pool_kernel_size: 5\n",
            "Training complete! train_accuracy: 0.682  val_accuracy: 0.657  train_loss: 0.576  val_loss: 0.646\n",
            "Starting model training... lr: 0.006181151057248816  epochs: 3  num_filters: 2  kernel_size: 66  pool_kernel_size: 36\n",
            "Training complete! train_accuracy: 0.671  val_accuracy: 0.642  train_loss: 0.593  val_loss: 0.679\n",
            "Starting model training... lr: 0.016573021688128242  epochs: 1  num_filters: 7  kernel_size: 86  pool_kernel_size: 89\n",
            "Training complete! train_accuracy: 0.629  val_accuracy: 0.6  train_loss: 0.642  val_loss: 0.631\n",
            "Starting model training... lr: 0.004535016955838373  epochs: 3  num_filters: 3  kernel_size: 36  pool_kernel_size: 20\n",
            "Training complete! train_accuracy: 0.672  val_accuracy: 0.656  train_loss: 0.59  val_loss: 0.672\n",
            "Starting model training... lr: 0.0045078505519100896  epochs: 3  num_filters: 9  kernel_size: 97  pool_kernel_size: 34\n",
            "Training complete! train_accuracy: 0.685  val_accuracy: 0.644  train_loss: 0.579  val_loss: 0.671\n",
            "Starting model training... lr: 0.005699374602815057  epochs: 1  num_filters: 3  kernel_size: 68  pool_kernel_size: 20\n",
            "Training complete! train_accuracy: 0.675  val_accuracy: 0.646  train_loss: 0.592  val_loss: 0.646\n",
            "Starting model training... lr: 0.005418191865879004  epochs: 5  num_filters: 7  kernel_size: 85  pool_kernel_size: 29\n",
            "Training complete! train_accuracy: 0.681  val_accuracy: 0.641  train_loss: 0.583  val_loss: 0.661\n",
            "Starting model training... lr: 0.01037539618283833  epochs: 4  num_filters: 2  kernel_size: 6  pool_kernel_size: 22\n",
            "Training complete! train_accuracy: 0.657  val_accuracy: 0.669  train_loss: 0.609  val_loss: 0.654\n",
            "Starting model training... lr: 0.003230801447038454  epochs: 1  num_filters: 6  kernel_size: 32  pool_kernel_size: 91\n",
            "Training complete! train_accuracy: 0.667  val_accuracy: 0.655  train_loss: 0.6  val_loss: 0.679\n",
            "Starting model training... lr: 0.01645991900526921  epochs: 5  num_filters: 2  kernel_size: 83  pool_kernel_size: 68\n",
            "Training complete! train_accuracy: 0.664  val_accuracy: 0.64  train_loss: 0.603  val_loss: 0.654\n",
            "Starting model training... lr: 0.011349603942238228  epochs: 2  num_filters: 3  kernel_size: 16  pool_kernel_size: 76\n",
            "Training complete! train_accuracy: 0.662  val_accuracy: 0.656  train_loss: 0.605  val_loss: 0.645\n",
            "Starting model training... lr: 0.005770658579906897  epochs: 4  num_filters: 3  kernel_size: 64  pool_kernel_size: 73\n",
            "Training complete! train_accuracy: 0.607  val_accuracy: 0.562  train_loss: 0.656  val_loss: 0.692\n",
            "Starting model training... lr: 0.0039262682899382  epochs: 3  num_filters: 8  kernel_size: 78  pool_kernel_size: 38\n",
            "Training complete! train_accuracy: 0.682  val_accuracy: 0.643  train_loss: 0.582  val_loss: 0.661\n",
            "Starting model training... lr: 0.014273437844721376  epochs: 2  num_filters: 6  kernel_size: 99  pool_kernel_size: 85\n",
            "Training complete! train_accuracy: 0.667  val_accuracy: 0.636  train_loss: 0.602  val_loss: 0.639\n",
            "Starting model training... lr: 0.00906821596567223  epochs: 5  num_filters: 5  kernel_size: 46  pool_kernel_size: 36\n",
            "Training complete! train_accuracy: 0.675  val_accuracy: 0.644  train_loss: 0.589  val_loss: 0.658\n",
            "Starting model training... lr: 0.010408683401261887  epochs: 3  num_filters: 8  kernel_size: 65  pool_kernel_size: 95\n",
            "Training complete! train_accuracy: 0.663  val_accuracy: 0.638  train_loss: 0.605  val_loss: 0.649\n",
            "Starting model training... lr: 0.009323905843786586  epochs: 5  num_filters: 1  kernel_size: 42  pool_kernel_size: 60\n",
            "Training complete! train_accuracy: 0.606  val_accuracy: 0.563  train_loss: 0.658  val_loss: 0.694\n",
            "Starting model training... lr: 0.01326731119059768  epochs: 5  num_filters: 9  kernel_size: 17  pool_kernel_size: 59\n",
            "Training complete! train_accuracy: 0.666  val_accuracy: 0.656  train_loss: 0.602  val_loss: 0.648\n",
            "Starting model training... lr: 0.013028994988626617  epochs: 5  num_filters: 2  kernel_size: 95  pool_kernel_size: 38\n",
            "Training complete! train_accuracy: 0.61  val_accuracy: 0.561  train_loss: 0.656  val_loss: 0.702\n",
            "Starting model training... lr: 0.010618891442221976  epochs: 1  num_filters: 4  kernel_size: 26  pool_kernel_size: 11\n",
            "Training complete! train_accuracy: 0.626  val_accuracy: 0.618  train_loss: 0.65  val_loss: 0.619\n",
            "Starting model training... lr: 0.011515902672648248  epochs: 4  num_filters: 8  kernel_size: 69  pool_kernel_size: 79\n",
            "Training complete! train_accuracy: 0.678  val_accuracy: 0.647  train_loss: 0.588  val_loss: 0.658\n",
            "Starting model training... lr: 0.009800054363553957  epochs: 3  num_filters: 2  kernel_size: 50  pool_kernel_size: 17\n",
            "Training complete! train_accuracy: 0.668  val_accuracy: 0.649  train_loss: 0.601  val_loss: 0.62\n",
            "Starting model training... lr: 0.006641871460009682  epochs: 5  num_filters: 6  kernel_size: 50  pool_kernel_size: 98\n",
            "Training complete! train_accuracy: 0.677  val_accuracy: 0.643  train_loss: 0.586  val_loss: 0.667\n",
            "Starting model training... lr: 0.007423867854693004  epochs: 3  num_filters: 6  kernel_size: 60  pool_kernel_size: 57\n",
            "Training complete! train_accuracy: 0.671  val_accuracy: 0.643  train_loss: 0.592  val_loss: 0.65\n",
            "Starting model training... lr: 0.015920035896319525  epochs: 5  num_filters: 4  kernel_size: 38  pool_kernel_size: 48\n",
            "Training complete! train_accuracy: 0.673  val_accuracy: 0.653  train_loss: 0.592  val_loss: 0.648\n",
            "0 :  0.6685983827493261  lr:  0.01037539618283833  epochs: 4  num_filters: 2  kernel_size: 6  pool_kernel_size: 22\n",
            "1 :  0.6598113207547169  lr:  0.010850930040418889  epochs: 3  num_filters: 3  kernel_size: 12  pool_kernel_size: 22\n",
            "2 :  0.6588409703504043  lr:  0.013166648935463706  epochs: 4  num_filters: 6  kernel_size: 66  pool_kernel_size: 16\n",
            "3 :  0.6582749326145553  lr:  0.017860190015564006  epochs: 3  num_filters: 7  kernel_size: 39  pool_kernel_size: 34\n",
            "4 :  0.6566576819407008  lr:  0.0024972920696599834  epochs: 4  num_filters: 5  kernel_size: 48  pool_kernel_size: 5\n",
            "5 :  0.6565498652291105  lr:  0.004604750158706846  epochs: 5  num_filters: 7  kernel_size: 91  pool_kernel_size: 5\n",
            "6 :  0.6564690026954177  lr:  0.01326731119059768  epochs: 5  num_filters: 9  kernel_size: 17  pool_kernel_size: 59\n",
            "7 :  0.6563072776280323  lr:  0.0021537015336468646  epochs: 5  num_filters: 5  kernel_size: 6  pool_kernel_size: 83\n",
            "8 :  0.6562264150943397  lr:  0.01063382782120029  epochs: 4  num_filters: 7  kernel_size: 33  pool_kernel_size: 23\n",
            "9 :  0.6559568733153639  lr:  0.011349603942238228  epochs: 2  num_filters: 3  kernel_size: 16  pool_kernel_size: 76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1Q2LGd2ZAkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "db7143f7-1017-4638-8178-588014e802c7"
      },
      "source": [
        "a, b, c, d, model = train_model(0.01, 4, 250, 2, 6, 22, True)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting model training... lr: 0.01  epochs: 4  num_filters: 2  kernel_size: 6  pool_kernel_size: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training complete! train_accuracy: 0.656  val_accuracy: 0.666  train_loss: 0.608  val_loss: 0.664\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}