# ShroomNet
Data Preprocessing and ML Models to Predict Psilocybin Intoxication Based on Brainwaves

A binary classifier that predicts psilocybin intoxication based on brainwaves. 

## Data
Data comes from a Swiss study where subjects were administered high doses, low doses, and placebo doses of psilocybin and 
presented a range auditory and visual stimulus while their EEG was recorded. There are only 22 subjects, posing a significant
challenge in creating a model that can generalize to new unseen subjects. At this point in time, I do not have permission to 
release the dataset. 

## Pre-processing: 
The data was preprocessed in EEGLAB, where it was downsampled significantly to 125 HZ with low-pass filtering to 
prevent aliasing. For now, each EEG channel is treated as its own separate 1-D time series, rather than the true multivariate 
spatial time series represented by many channels placed at various positions across the scalp. While treating each channel 
as an independent time series neglects the spatial relationships between channels, it simplifies the model significantly and 
also provides much more training examples. Since there are 64 channels, treating each channel separately increases the number 
of training examples available 64 fold. 

The data is split into train/test sets by designating a subset of the research participants for the training set, and making
the rest of the subjects the test set. To perform well on the test set, the model must generalize to subjects it has never
seen during training. 

Input sequences are fixed length 1-D sequences of Voltage over time at an electrode. Each sequence is standardized using the
rule standardVec = (vec - mean)/stdev. 

## Models:
Models in consideration include LSTM and 1-D convolutional neural networks. The most promising model so far is the data cleaning model.

## Data Cleaning Model:
This model attempts to mimic part of the EEG data cleaning process performed in the lab. Input is 3D time series, where each dimension is a channel of EEG recording from a random time and channel from a given participant after they consumed either psilocybin or placebo. First, a 1-D convolutional layer with shared filters across all 3 dimensions attempts to identify which of the 3 input channels would result in best classification performance. Then, an LSTM model predicts state of intoxication separately for each channel, and weights these 3 predictions using a softmax of the convolutional channel selection output.

## Results:
In progress... Validation set performance on subjects unseen during training is around 64%. It is important to note that this measures percentage of datapoints that are correctly classified as coming from a person who has ingested psilocybin or not. This does not mean psilocybin can be detected for 64% of subjects. Since each subject produces thousands of datapoints every few minutes during an EEG recording, if 64% performance is consistent for datapoints accross all subjects, then this method could predict psilocybin influence significantly more accurately than 64% through analysis of the large dataset produced during an individual EEG recording. To determine if this high classification accuracy for individuals is possible, I will have to evaluate performance for each of the subjects in my test set. 

## Discussion:
Even simple LSTM models seem to be able to determine state of psilocybin intoxication based on Voltage at the scalp. Is this
due to some deep understanding of brain activity as it is altered by magic mushrooms? Maybe not... EEG data has a 
notoriously poor signal to noise ratio, and much of the signal picked up by EEG is actually generated by the muscles,
not the brain. This could include heart-rate, eye blinks, eye movement, fidgeting, and more. So it's very possible that 
all ShroomNet knows is that a participant on mushrooms is blinking a bunch and freaking out. EEG research often involves 
complex preprocessing to remove eye-blinks, remove long-term linear trends, remove wandering channels, subtract a reference electrode, use spatial information to create independent components... etc. The amazing thing about this model is that it 
works without any of this complex preprocessing. While this is convenient, it also casts some doubt as to whether the model
is learning from brain activity some other signal, or a mix of both. 
