{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG Data Preprocess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU4mL8qQ3KMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oHey4nkV0BL",
        "colab_type": "code",
        "outputId": "3e969655-cd29-433b-a138-7bdcec040957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmD2ZElCtSQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Read data from txt format produced by EEGLAB to numpy array and optionally save numpy arrays to CSV in Google Drive ###\n",
        "pathInMyDrive = \"PsiloClassifier/txtDownsampledData/\"\n",
        "pathToSaveData = \"PsiloClassifier/dataSplit/\"\n",
        "\n",
        "allSubjects = [\"01\", \"02\", \"04\", \"05\", \"08\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
        "testSubjects = [\"02\", \"08\", \"15\", \"23\"]\n",
        "trainSubjects = [x for x in allSubjects if x not in testSubjects]\n",
        "\n",
        "selectEveryNthChannelN = 5\n",
        "sampleLength = 250\n",
        "saveToDisk = False\n",
        "\n",
        "trainX, trainY, testX, testY = load(selectEveryNthChannelN, sampleLength)\n",
        "\n",
        "if(saveToDisk):\n",
        "  np.savetxt(pathToSaveData + \"trainX.csv\", trainX, delimiter=\",\")\n",
        "  np.savetxt(pathToSaveData + \"trainY.csv\", trainY, delimiter=\",\")\n",
        "  np.savetxt(pathToSaveData + \"testX.csv\", testX, delimiter=\",\")\n",
        "  np.savetxt(pathToSaveData + \"testY.csv\", testY, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_n8qOgTHmLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(selectEveryNthChannelN, sampleLength):\n",
        "  trainXPlacebo, trainYPlacebo = loadProcess(trainSubjects, \"PL\", selectEveryNthChannelN, sampleLength)\n",
        "  trainXHD, trainYHD = loadProcess(trainSubjects, \"HD\", selectEveryNthChannelN, sampleLength)\n",
        "  trainX, trainY = catAndShuffleData(trainXPlacebo, trainYPlacebo, trainXHD, trainYHD)\n",
        "\n",
        "  testXPlacebo, testYPlacebo = loadProcess(testSubjects, \"PL\", selectEveryNthChannelN, sampleLength)\n",
        "  testXHD, testYHD = loadProcess(testSubjects, \"HD\", selectEveryNthChannelN, sampleLength)\n",
        "  testX, testY = catAndShuffleData(testXPlacebo, testYPlacebo, testXHD, testYHD)\n",
        "\n",
        "  return trainX, trainY, testX, testY;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5drdmbwOR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadProcess(subjectList, dose, selectEveryNthChannelN, sampleLength):\n",
        "  x = loadDownsampledDataFromSubjectListAndDose(subjectList, dose)\n",
        "  x = keepEveryNthDataChannel(x, selectEveryNthChannelN)\n",
        "  x = segmentChannelsIntoVectors(x, sampleLength)\n",
        "  x = standardizeDataVectors(x)\n",
        "  y = []\n",
        "  if dose == \"PL\":\n",
        "    for i in range(len(x)):\n",
        "      y.append(np.zeros(1))\n",
        "  else:\n",
        "    for i in range(len(x)):\n",
        "      y.append(np.ones(1))\n",
        "  type(x)\n",
        "  type(y)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  return x, y;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yRpVjm4YQ6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadDownsampledDataFromSubjectListAndDose(subjectList, dose):\n",
        "  dataList = []\n",
        "  for i in subjectList:\n",
        "    filename = \"S\" + i + \"_P300_\" + dose + \"_125.txt\"\n",
        "    dataList.append(loadtxt(pathInMyDrive + filename,  delimiter='\\t'))\n",
        "  return dataList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtAspHsDcXml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keepEveryNthDataChannel(subjectDataList, n):\n",
        "  dataList = []\n",
        "  for subjectDataset in subjectDataList:\n",
        "    dataList.append(subjectDataset[:, 0::n])\n",
        "  return dataList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1eD6E4k0QYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentChannelsIntoVectors(subjectDataList, vectorLength):\n",
        "  dataVectors = []\n",
        "  for subjectDataset in subjectDataList:\n",
        "    for channel in range(np.size(subjectDataset, 1)):\n",
        "      time = int(np.random.uniform(0, vectorLength))\n",
        "      while (time + vectorLength) < np.size(subjectDataset, 0):\n",
        "        dataVectors.append(subjectDataset[time : time + vectorLength , channel])\n",
        "        time = time + vectorLength                  \n",
        "  return dataVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkI2HujlGr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardizeDataVectors(dataVectorList):\n",
        "  dataVectors = []\n",
        "  for vec in dataVectorList:\n",
        "    mean = np.mean(vec)\n",
        "    stdev = np.std(vec)\n",
        "    standardVec = (vec - mean)/stdev\n",
        "    dataVectors.append(standardVec)\n",
        "  return dataVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNXbZuM9G33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def catAndShuffleData(x0, y0, x1, y1):\n",
        "  x = np.concatenate((x0, x1), axis=0)\n",
        "  y = np.concatenate((y0, y1), axis=0)\n",
        "\n",
        "  x, y = shuffle(x, y)\n",
        "\n",
        "  return x, y;"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}